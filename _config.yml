# -----------------------------------------------------------------------------
# Site settings
# -----------------------------------------------------------------------------

title: blank
name: ML Evaluation Standards
first_name: ML
middle_name: 
last_name: Evaluation Standards
email:
description: > # the ">" symbol means to ignore newlines until "footer_text:"
  A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
footer_text: >
  Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
  Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.
  Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.
keywords: jekyll, jekyll-theme, academic-website, portfolio-website  # add your own keywords or leave empty

lang: en # the language of your site (for example: en, fr, cn, ru, etc.)
icon: üî• # the emoji used as the favicon
url: # the base hostname & protocol for your site
baseurl: # the subpath of your site, e.g. /blog/
last_updated: false # set to true if you want to display last updated in the footer
impressum_path:  # set to path to include impressum link in the footer, use the same path as permalink in a page, helps to conform with EU GDPR

# -----------------------------------------------------------------------------
# RSS Feed
# -----------------------------------------------------------------------------
# will use title and url fields
# Take a look to https://github.com/jekyll/jekyll-feed for more customization

# -----------------------------------------------------------------------------
# Layout
# -----------------------------------------------------------------------------

navbar_fixed: true
footer_fixed: true

# Dimensions
max_width: 800px

# TODO: add layout settings (single page vs. multi-page)

# -----------------------------------------------------------------------------
# Open Graph & Schema.org
# -----------------------------------------------------------------------------
# Display links to the page with a preview object on social media.
serve_og_meta: false # Include Open Graph meta tags in the HTML head
serve_schema_org: false # Include Schema.org in the HTML head
og_image: # The site-wide (default for all links) Open Graph preview image

# -----------------------------------------------------------------------------
# Social integration
# -----------------------------------------------------------------------------

github_username: ml-eval-standards # your GitHub user name
gitlab_username: # your GitLab user name
twitter_username: # your Twitter handle
linkedin_username: # your LinkedIn user name
scholar_userid: # your Google Scholar ID
orcid_id: # your ORCID ID
medium_username: # your Medium username
quora_username: # your Quora username
publons_id: # your ID on Publons
research_gate_profile: # your profile on ResearchGate
blogger_url: # your blogger URL
work_url: # work page URL
keybase_username: # your keybase user name
wikidata_id: # your wikidata id
dblp_url: # your DBLP profile url
stackoverflow_id: #your stackoverflow id

rss_icon: true

contact_note: >
  You can even add a little note about which of these is the best way to reach you.

google_analytics:  # your google-analytics ID (format: UA-XXXXXXXXX)
google_site_verification:  # your google-site-verification ID (Google Search Console)
bing_site_verification:  # out your bing-site-verification ID (Bing Webmaster)
panelbear_analytics:  # panelbear analytics site ID (format: XXXXXXXXX)

# -----------------------------------------------------------------------------
# Blog
# -----------------------------------------------------------------------------

blog_name: # your blog must have a name for it to show up in the nav bar
blog_description: a simple whitespace theme for academics
permalink: /blog/:year/:title/

# Pagination
pagination:
  enabled: true

# Comments
disqus_shortname: al-folio # put your disqus shortname
# https://help.disqus.com/en/articles/1717111-what-s-a-shortname

# -----------------------------------------------------------------------------
# Collections
# -----------------------------------------------------------------------------

collections:
  news:
    defaults:
      layout: post
    output: true
    permalink: /news/:path/
  projects:
    output: true
    permalink: /projects/:path/

news_limit: 5

# -----------------------------------------------------------------------------
# Jekyll settings
# -----------------------------------------------------------------------------

# Markdown and syntax highlight
markdown: kramdown
highlighter: rouge
highlight_theme: github  # https://github.com/jwarby/jekyll-pygments-themes
kramdown:
  input: GFM
  syntax_highlighter_opts:
    css_class: 'highlight'
    span:
      line_numbers: false
    block:
      line_numbers: false
      start_line: 1

# Includes & excludes
include: ['_pages']
exclude:
  - bin
  - Gemfile
  - Gemfile.lock
  - vendor
keep_files:
  - CNAME
  - .nojekyll
  - .git

# Plug-ins
plugins:
  - jekyll-archives
  - jekyll-diagrams
  - jekyll-email-protect
  - jekyll-feed
  - jekyll-github-metadata
  - jekyll-imagemagick
  - jekyll-paginate-v2
  - jekyll/scholar
  - jekyll-sitemap
  - jekyll-target-blank
  - jekyll-twitter-plugin
  - jemoji

# Sitemap settings
defaults:
  - scope:
      path:            "assets/**/*.*"
    values:
      sitemap:         false
# Extras
github: [metadata]

# -----------------------------------------------------------------------------
# Jekyll optimization
# -----------------------------------------------------------------------------

# HTML remove comments (<!-- .... -->)
remove_HTML_comments: false

# HTML beautifier (_plugins/beautify.rb) / https://github.com/threedaymonk/htmlbeautifier
beautify: false # This function has conflict with the code snippets, they can be displayed incorrectly

# HTML minify (_plugins/minify.rb) Thanks to: https://www.ffbit.com/blog/2021/03/17/html-minification-in-jekyll.html
minify: false

# CSS/SASS minify
sass:
  style: compressed

# -----------------------------------------------------------------------------
# Jekyll Archives
# -----------------------------------------------------------------------------

jekyll-archives:
  enabled: [year, tags, categories] # enables year, tag and category archives (remove if you need to disable one of them). 
  layouts:
    year: archive-year
    tag: archive-tag
    category: archive-category
  permalinks:
    year: '/blog/:year/'
    tag: '/blog/tag/:name/'
    category: '/blog/category/:name/'

# -----------------------------------------------------------------------------
# Jekyll Scholar
# -----------------------------------------------------------------------------

scholar:

  last_name: Einstein
  first_name: [Albert, A.]

  style: apa
  locale: en

  source: /_bibliography/
  bibliography: papers.bib
  bibliography_template: bib
  # Note: if you have latex math in your bibtex, the latex filter
  # preprocessing may conflict with MathJAX if the latter is enabled.
  # See https://github.com/alshedivat/al-folio/issues/357.
  bibtex_filters: [latex, smallcaps, superscript]

  replace_strings: true
  join_strings: true

  details_dir: bibliography
  details_layout: bibtex.html
  details_link: Details

  query: "@*"


# -----------------------------------------------------------------------------
# Responsive WebP Images
# -----------------------------------------------------------------------------

imagemagick:
  enabled: false
  widths:
    - 480
    - 800
    - 1400
  input_directories:
    - assets/img
  input_formats:
    - ".jpg"
    - ".jpeg"
    - ".png"
    - ".tiff"
  output_formats:
    webp: "-quality 75%"

# -----------------------------------------------------------------------------
# Jekyll Diagrams
# -----------------------------------------------------------------------------

jekyll-diagrams:
    # configuration, see https://github.com/zhustec/jekyll-diagrams.
    # feel free to comment out this section if not using jekyll diagrams.


# -----------------------------------------------------------------------------
# Optional Features
# -----------------------------------------------------------------------------

enable_google_analytics:    false  # enables google analytics
enable_panelbear_analytics: false  # enables panelbear analytics
enable_google_verification: false  # enables google site verification
enable_bing_verification:   false  # enables bing site verification
enable_mansory:             true   # enables automatic project cards arangement
enable_math:                true   # enables math typesetting (uses MathJax)
enable_tooltips:            false  # enables automatic tooltip links generated
                                   # for each section titles on pages and posts
enable_darkmode:            true   # enables switching between light/dark modes
enable_navbar_social:       false  # enables displaying social links in the
                                   # navbar on the about page
enable_project_categories:  true   # enables categorization of projects into
                                   # multiple categories
enable_medium_zoom:         true   # enables image zoom feature (as on medium.com)


# -----------------------------------------------------------------------------
# Library versions
# -----------------------------------------------------------------------------

academicons:
  version: "1.9.0"
  integrity: "sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg=="
bootstrap:
  version: "4.5.2"
  integrity:
    css: "sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg=="
    js: "sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ=="
fontawesome:
  version: "5.14.0"
  integrity: "sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog=="
jquery:
  version: "3.5.1"
  integrity: "sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg=="
mathjax:
  version: "3.2.0"
mansory:
  version: "4.2.2"
  integrity: "sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI="
mdb:
  version: "4.19.1"
  integrity:
    css: "sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q=="
    js: "sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw=="
popper:
  version: "2.4.4"
  integrity: "sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A=="
medium_zoom:
  version: "1.0.6"
  integrity: "sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM="


# -----------------
# Organizers
# -----------------
organizers: [
    {'name': 'Stephanie Chan',
    'website': 'https://scholar.google.com/citations?hl=en&user=bXOt49QAAAAJ',
    'affiliations': 'DeepMind',
    'img_path': "https://thecatapi.com/api/images/get?format=src&type=gif&timestamp=1"},
    {'name': 'Rishabh Agarwal',
    'website': 'https://agarwl.github.io',
    'affiliations': 'Google Brain',
    'img_path': "https://thecatapi.com/api/images/get?format=src&type=gif&timestamp=2"},
    {'name': 'Xavier Bouthillier',
    'website': 'https://bouthilx.github.io',
    'affiliations': 'Mila, Universit√© de Montr√©al',
    'img_path': "https://thecatapi.com/api/images/get?format=src&type=gif&timestamp=3"},
    {'name': 'Caglar Gulcehre',
    'website': 'https://caglarg.com',
    'affiliations': 'DeepMind',
    'img_path': "https://thecatapi.com/api/images/get?format=src&type=gif&timestamp=4"},
    {'name': 'Jesse Dodge',
    'website': 'http://www.cs.cmu.edu/~jessed/',
    'affiliations': 'Allen Institute for AI',
    'img_path': "https://thecatapi.com/api/images/get?format=src&type=gif&timestamp=5"},
]

speakers: [
    {'name': 'Thomas Wolf',
    'anchor': 'thomas_wolf',
    'website': 'https://thomwolf.io',
    'affiliations': 'Hugginface Inc.',
    'img_path':"assets/img/thomas_wolf.jpg",
    'time': '12h15',
    'title': 'TDB',
    'abstract': 'TBD',
    'bio':'<p>Thomas Wolf is co-founder and Chief Science Officer of HuggingFace. The tools created by Thomas Wolf and the HuggingFace team are used across more than 5000 research organisations including Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, the Allen Institute for Artificial Intelligence as well as most university departments.</p><p>Thomas Wolf is the initiator and senior chair of the largest research collaboration that has ever existed in Artificial Intelligence: <a href="https://bigscience.huggingface.co">‚ÄúBigScience‚Äù</a> as well as a set of widely used libraries and tools (<a href="https://github.com/huggingface/">huggingface</a>).</p><p>Thomas Wolf is also a prolific educator and a thought leader in the field of Artificial Intelligence and Natural Language Processing, a regular invited speaker to conferences all around the world.</p>'},
    &frank_schneider {'name': 'Frank Schneider',
    'anchor': 'frank_schneider',
    'website': 'http://fsschneider.github.io',
    'affiliations': 'University of T√ºbingen',
    'title': 'Improving Optimizer Evaluation in Deep Learning',
    'time': '13h00',
    'abstract': "<p>Although hundreds of optimization algorithms have been proposed for deep learning, there is no widely agreed-upon protocol for evaluating their efficiency, performance, and usability. Instead, the crucial choice of the optimizer is too often done based on personal anecdotes instead of grounded empirical evidence.</p><p>In this talk, we present strategies for comparing deep learning optimizers which consider the unique challenges of deep learning such as the inherent stochasticity or the crucial distinction between learning and pure optimization. These strategies are formalized and automatized in the Python package DeepOBS, which allows fairer, faster, and more convincing empirical comparisons of deep learning optimizers.</p><p>Following this protocol, we report insights from our independent, third-party evaluation of the field's current state. A thorough comparison of fifteen popular deep learning optimizers, using roughly 50,000 individual runs, reveals that the comparably traditional Adam optimizer remains a strong but not dominating contender and that newer methods fail to consistently outperform it.</p><p>As an adjacent research direction to benchmarks, new debugging tools, such as Cockpit, allow for a more detailed evaluation of the training process of neural networks beyond just the loss or the model's performance. These tools could disentangle the many factors contributing to (un)successful neural network training, helping us understand whether training improvements are the result of better models, better algorithms, or better hyperparameters.</p>",
    'img_path':"assets/img/frank_schneider.jpg",
    'bio': "Frank Schneider is a Ph.D. student in the Methods of Machine Learning group supervised by Prof. Dr. Philipp Hennig at the University of T√ºbingen in Germany. His research focuses on making deep learning more user-friendly. He has previously published work on new debugging tools for neural network training and on improving the evaluation process of optimization algorithms for deep learning. He is currently a co-chair of the MLCommons‚Ñ¢ Algorithms Working Group. He holds a Bachelor's and Master's degree in Simulation Technology from the University of Stuttgart as well as a Master's degree in Industrial and Applied Mathematics from the Eindhoven University of Technology."},
    # {'name': 'Phillipp Hennig',
    # 'anchor': 'phillipp_hennig',
    # 'website': '',
    # 'affiliations': 'University of T√ºbingen',
    # 'time': '13h00',
    # 'title': 'TDB',
    # 'abstract': 'TBD',
    # 'img_path':"assets/img/philipp_hennig.jpeg",
    # 'bio': ''},
    &rotem_dror {'name': 'Rotem Dror',
    'anchor': 'rotem_dror',
    'website': 'https://rtmdrr.github.io/',
    'affiliations': 'University of Pennsylvania',
    'img_path':"assets/img/rotem_dror.jpeg",
    'time': '13h45',
    'title': 'A Statistical Analysis of Automatic Evaluation Metrics for Summarization',
    'abstract': '<p>The quality of a summarization evaluation metric is quantified by calculating the correlation between its scores and human annotations across a large number of summaries. Currently, it is not clear how precise these correlation estimates are, nor whether differences between two metrics‚Äô correlations reflect a true difference or if it is due to random chance. In this talk, I will address these two problems by proposing methods for calculating confidence intervals and running hypothesis tests for correlations. After evaluating which of the proposed methods is most appropriate for summarization through two simulation experiments, I will analyze the results of applying these methods to several different automatic evaluation metrics across three sets of human annotations. In this research, we find that the confidence intervals are rather wide, demonstrating high uncertainty in how reliable automatic metrics truly are. Further, although many metrics fail to show statistical improvements over ROUGE, two recent works, QAEval and BERTScore, do in some evaluation settings. This work is published at <a href="https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00417/107833/A-Statistical-Analysis-of-Summarization-Evaluation">TACL 2021</a>.</p><p>In the second part of this talk, I will present an ongoing study that identifies two ways in which the definition of the system-level correlation is inconsistent with how metrics are used to evaluate summarization systems in practice and propose changes to rectify this disconnect. The results from these analyses point to the need for future research to focus on developing more consistent and reliable human evaluations of summaries.</p><p>This research was done in collaboration with Daniel Deutsch, a Ph.D. student from the Cognitive Computation Group at the Department of Computer and Information Science, University of Pennsylvania.</p>',
    'bio': 'Rotem Dror is a Postdoctoral Researcher at the Cognitive Computation Group at the Department of Computer and Information Science, University of Pennsylvania. She is working with Prof. Dan Roth. She has completed her Ph.D. in the Natural Language Processing Group, supervised by Prof. Roi Reichart, at the Faculty of Industrial Engineering and Management at the Technion - Israel Institute of Technology. In her Ph.D. thesis, she discussed Algorithms and Statistically Sound Evaluation of Structured Solutions in Natural Language Processing. For more information: <a href="https://rtmdrr.github.io/">rtmdrr.github.io</a>.'},
    &james_evans {'name': 'James Evans',
    'anchor': 'james_evans',
    'website': '',
    'affiliations': 'University of Chicago',
    'time': '16h35',
    'title': 'TDB',
    'abstract': 'TBD',
    'img_path':"assets/img/james_evans.png",
    'bio': ''},
   {'name': 'Melanie Mitchell',
    'anchor': 'melanie_mitchell',
    'website': 'https://melaniemitchell.me',
    'affiliations': 'Sante Fe Institute',
    'time': '18h50',
    'title': 'Beyond Accuracy:  How to Evaluate Understanding on Conceptual Abstraction Benchmarks',
    'abstract': 'The abilities to recognize abstract concepts (e.g. ‚Äúsame‚Äù vs. ‚Äúdifferent‚Äù) and make analogies is central to human intelligence, and has received increasing attention in the AI/ML community, with challenge domains such as Raven‚Äôs Progressive Matrices, Bongard Problems, and the Abstraction and Reasoning Corpus (ARC).  However, the methods typically used to evaluate ML systems on these domains have failed to assess true abstraction and generalization abilities, and have allowed for ‚Äúshortcut learning‚Äù that succeeds on a particular benchmark, but for the wrong reasons.   In this talk I will propose a different approach to evalution, one that attempts to test for degrees of ‚Äúunderstanding‚Äù of abstract concepts, beyond simple accuracy measures.',
    'img_path':"assets/img/melanie_mitchell.png",
    'bio': 'Melanie Mitchell is the Davis Professor of Complexity at the Santa Fe Institute. Her current research focuses on conceptual abstraction, analogy-making, and visual recognition in artificial intelligence systems.   Melanie is the author or editor of six books and numerous scholarly papers in the fields of artificial intelligence, cognitive science, and complex systems. Her book Complexity: A Guided Tour (Oxford University Press) won the 2010 Phi Beta Kappa Science Book Award and was named by Amazon.com as one of the ten best science books of 2009. Her latest book is Artificial Intelligence: A Guide for Thinking Humans (Farrar, Straus, and Giroux).'},
   {'name': 'Katherine Heller',
    'anchor': 'katherine_heller',
    'website': '',
    'affiliations': 'Google Brain',
    'time': '19h35',
    'title': 'A framework for improved ML evaluations',
    'abstract': 'I start by discussing ML evaluation goals versus current standards, followed by the presentation of a framework for better addressing these evaluation goals. This framework is comprised of three parts: 1) Qualitiative Evaluation, 2) Demographic Slicing, and 3) Distribution Shift and Causal Evaluations. I present "Healthsheets", a transparency artefact for health datasets, in the spirit of "Datasheets", as work towards improve qualitative evaluation. I will also discuss work on identifying underspecified models, where our model may not encode the causal structure we believe it does, in situations where distribution shift is a factor. We also look at fairness properties in distribution shift situations, and discuss transfer implications of models, when broken down by demographic group. Lastly, I will make a case for the importance of uncertainty and its implications for demographic fairness, discussing work on Electronic Health Record data, Bayesian neural networks, and differences in distributions of mortality predictions for various demographic groups.',
    'img_path':"assets/img/katherine_heller.jpeg",
    'bio': 'Katherine Heller is a Research Scientist in the Responsible AI organization in Google Research. She leads the Context in AI Research (CAIR) group, which focuses on understanding the *context* in which are AI systems are being developed and deployed. Prior to Google, she was faculty in the Statistical Science department at Duke university, where she collaborated across many disciplines to release a sepsis detection system (SepsisWatch), to the Emergency Departments of Duke University hospitals. SepsisWatch has now been run on over 200k patients. She also engaged in many other projects there, through an NSF CAREER, and other awards. Katherine received her PhD from the Gatsby Computational Neuroscience Unit at UCL, and was a postdoctoral fellow at the University of Cambridge and MIT.'},
    &corinna_cortes {'name': 'Corinna Cortes',
    'anchor': 'corinna_cortes',
    'website': 'https://research.google/people/author121/',
    'affiliations': 'Google Research NYC',
    'time': '20h20',
    'title': 'Inconsistency in Conference Peer Review: Revisiting the 2014 NeurIPS Experiment',
    'abstract': '<p>In this talk we revisit the 2014 NeurIPS experiment that examined inconsistency in conference peer review. We determine that 50% of the variation in reviewer quality scores was subjective in origin. Further, with 7+ years passing since the experiment we find that for accepted papers, there is no correlation between quality scores and impact of the paper as measured as a function of citation count. We trace the fate of rejected papers, recovering where these papers were eventually published. For these papers we find a correlation between quality scores and impact. We conclude that the reviewing process for the 2014 conference was good for identifying poor papers, but poor for identifying good papers.</p><p>This 2014 NeurIPS experiment was repeated by the 2021 NeurIPS Program Chairs and we compare the findings. We also discuss other experiments carried out by ICML Program Chairs.</p><p>We hope the findings and some of the ideas from the experiments will help to design a better peer-review pipeline in future conferences.</p>',
    'img_path':"assets/img/corinna_cortes.png",
    'bio':"Corinna Cortes is a VP of Google Research, NY, where she is working on a broad range of theoretical and applied large-scale machine learning problems. Prior to Google, Corinna spent more than ten years at AT&T Labs - Research, formerly AT&T Bell Labs, where she held a distinguished research position. Corinna's research work is well-known in particular for her contributions to the theoretical foundations of support vector machines (SVMs), for which she jointly with Vladimir Vapnik received the 2008 Paris Kanellakis Theory and Practice Award, and her work on data-mining in very large data sets for which she was awarded the AT&T Science and Technology Medal in the year 2000. Corinna received her MS degree in Physics from University of Copenhagen and joined AT&T Bell Labs as a researcher in 1989. She received her Ph.D. in computer science from the University of Rochester in 1993. Corinna is also a competitive runner, and a mother of two."}
]

panels: [
    {'name': 'Reproducibility and Rigor in ML',
    'anchor': 'reproducibility_and_rigor_in_ml',
    'moderator': 'Rishabh Agarwal',
    'description': "Example of questions we would like to cover are: What is reproducibility? What is it useful for and is it necessary for machine learning research? Are we in a different position with respect to other scientific fields because of e.g. the speed of iteration, a culture of open source, and stronger control over our experiments (compared to the natural sciences)? Should we embrace more statistical tools of other scientific domains, or are current  benchmarking methods sufficiently reliable? How much rigor is needed for ML?",
    'panelists': [
        *rotem_dror,
        {'name': 'Sara Hooker',
        'website': 'https://www.sarahooker.me/',
        'affiliations': 'Google Brain',
        'img_path':"assets/img/sara_hooker.png",
        'bio': 'Sara Hooker is a research scholar at Google Brain. Her research interests include interpretability, model compression and security in deep neural networks. In 2014, Sara founded Delta Analytics, a non-profit dedicated to building technical capacity to help communities across the world use machine learning. In 2014, she founded Delta Analytics, a non-profit dedicated to bringing technical capacity to help non-profits across the world use machine learning for good. She grew up in Mozambique, Lesotho, Swaziland, South Africa, and Kenya and currently resides in California.'},
        {'name': 'Koustuv Sinha',
        'website': 'https://www.cs.mcgill.ca/~ksinha4/',
        'affiliations': 'Mila, McGill University',
        'img_path':"assets/img/koustuv_sinha.jpg",
        'bio': 'Koustuv Sinha is a PhD Candidate at McGill University / Mila, supervised by Joelle Pineau. Koustuv‚Äôs research focuses on investigating systematicity in natural language understanding (NLU) models, especially the state-of-the-art large language models. His research goal is to develop methods to analyze the failure cases in robustness and systematicity of these NLU models, and develop methods to alleviate them in production. He is the organizer of the annual ML Reproducibility Challenge since 2018, and serves as an associate editor in ReScience journal. He has also served as Reproducibility Chair at NeurIPS in 2019 and 2020'},
        *frank_schneider,
        {'name': 'Ga√´l Varoquaux',
        'website': 'http://gael-varoquaux.info/',
        'affiliations': 'INRIA',
        'img_path':"assets/img/gael_varoquaux.jpg",
        'bio': 'Ga√´l Varoquaux is a research director working on data science and health at Inria (French Computer Science National research). His research focuses on statistical-learning tools for data science and scientific inference, with an eye on applications in health and social science. He develops tools to make machine learning easier, with statistical models suited for real-life, uncurated data, and software for data science. For example, since 2008, he has been exploring data-intensive approaches to understand brain function and mental health. He co-funded scikit-learn, one of the reference machine-learning toolboxes, and helped build various central tools for data analysis in Python. Varoquaux has a PhD in quantum physics and is a graduate from Ecole Normale Superieure, Paris.'}
        ]
    },
    {'name': 'Slow vs Fast Science',
    'anchor': 'slow_vs_fast_science',
    'moderator': 'Xavier Bouthillier',
    'description': "Examples of questions we would like to cover are: Slow or fast science, is this a false dichotomy? Is the slow-science movement a threat for exploration? Or is the current pace of publication becoming overwhelming, harming the dissemination of knowledge? Should we look for incentives to balance so-called ‚Äòslow‚Äô and ‚Äòfast‚Äô approaches and if so how could we evaluate what would be a proper balance?",
    'panelists': [
        {'name': 'Chelsea Finn',
        'website': 'https://ai.stanford.edu/~cbfinn/',
        'affiliations': 'Stanford University',
        'img_path':"assets/img/chelsea_finn.jpg",
        'bio': "Chelsea Finn is an Assistant Professor in Computer Science and Electrical Engineering at Stanford University, and the William George and Ida Mary Hoover Faculty Fellow. Finn's research interests lie in the capability of robots and other agents to develop broadly intelligent behavior through learning and interaction. To this end, her work has included deep learning algorithms for concurrently learning visual perception and control in robotic manipulation skills, inverse reinforcement methods for learning reward functions underlying behavior, and meta-learning algorithms that can enable fast, few-shot adaptation in both visual perception and deep reinforcement learning. Finn received her Bachelor's degree in Electrical Engineering and Computer Science at MIT and her PhD in Computer Science at UC Berkeley. Her research has been recognized through the Microsoft Research Faculty Fellowship, the IEEE RAS Early Academic Career Award, the ONR Young Investigator Award, the ACM doctoral dissertation award, and the MIT Technology Review 35 under 35 Award, and her work has been covered by various media outlets, including the New York Times, Wired, and Bloomberg. Throughout her career, she has sought to increase the representation of underrepresented minorities within CS and AI by developing an AI outreach camp at Berkeley for underprivileged high school students, a mentoring program for underrepresented undergraduates across four universities, and leading efforts within the WiML and Berkeley WiCSE communities of women researchers."},
        {'name': 'Michela Paganini',
        'website': 'https://mickypaganini.github.io',
        'affiliations': 'DeepMind',
        'img_path':"assets/img/michela_paganini.jpeg",
        'bio': ''},
        *james_evans,
        {'name': 'Russel Poldrack',
        'website': 'https://poldracklab.stanford.edu',
        'affiliations': 'Stanford University',
        'img_path':"assets/img/russel_poldrack.jpg",
        'bio': 'Russell Poldrack is a Professor in the Stanford Department of Psychology, Associate Director of Stanford Data Science, and Director of the Center for Open and Reproducible Science (CORES). His laboratory‚Äôs basic research focuses on understanding the brain systems involved in decision making and self control in humans using neuroimaging and behavioral methods. The laboratory has also developed a number of resources for open and reproducible science, including the OpenNeuro data sharing platform and the fMRIPrep preprocessing workflow.'},
        {'name': 'Oriol Vinyals',
        'website': 'https://research.google/people/OriolVinyals/',
        'affiliations': 'DeepMind',
        'img_path':"assets/img/oriol_vinyals.jpg",
        'bio': 'Oriol Vinyals is a Principal Scientist at Google DeepMind, and a team lead of the Deep Learning group. His work focuses on Deep Learning and Artificial Intelligence. Prior to joining DeepMind, Oriol was part of the Google Brain team. He holds a Ph.D. in EECS from the University of California, Berkeley and is a recipient of the 2016 MIT TR35 innovator award. His research has been featured multiple times at the New York Times, Financial Times, WIRED, BBC, etc., and his articles have been cited over 70000 times. His academic involvement includes program chair for the International Conference on Learning Representations (ICLR) of 2017, and 2018. He has also been an area chair for many editions of the NeurIPS and ICML conferences. Some of his contributions such as seq2seq, knowledge distillation, or TensorFlow are used in Google Translate, Text-To-Speech, and Speech recognition, serving billions of queries every day, and he was the lead researcher of the AlphaStar project, creating an agent that defeated a top professional at the game of StarCraft, achieving Grandmaster level, also featured as the cover of Nature. At DeepMind he continues working on his areas of interest, which include artificial intelligence, with particular emphasis on machine learning, deep learning and reinforcement learning.'}
        ]
    },
    {'name': 'Incentives for Better Evaluation',
    'anchor': 'incentives_for_better_eval',
    'moderator': 'Stephanie Chan',
    'description': "Examples of questions we would like to cover are: What are the pain-points for which we would need new/better incentives to improve the situation? What roles are the conferences and journals playing to improve these pain-points? Are we investing enough effort to monitor and identify issues in the review process? Is it acceptable to increase the workload of reviewers and ACs in order to gather data about the review process? Would a tighter loop between research and production lead to greater accountability?",
    'panelists': [
        *corinna_cortes,
        {'name': 'Yoshua Bengio',
        'website': 'https://yoshuabengio.org/',
        'affiliations': 'Mila, Universit√© de Montr√©al',
        'img_path':"assets/img/yoshua_bengio.jpg",
        'bio': 'Recognized worldwide as one of the leading experts in artificial intelligence, Yoshua Bengio is most known for his pioneering work in deep learning, earning him the 2018 A.M. Turing Award, ‚Äúthe Nobel Prize of Computing,‚Äù with Geoffrey Hinton and Yann LeCun. He is a Full Professor at Universit√© de Montr√©al, and the Founder and Scientific Director of Mila ‚Äì Quebec AI Institute. He co-directs the CIFAR Learning in Machines & Brains program as Senior Fellow and acts as Scientific Director of IVADO. In 2019, he was awarded the prestigious Killam Prize and in 2021, became the second most cited computer scientist in the world. He is a Fellow of both the Royal Society of London and Canada, Knight of the Legion of Honor of France and Officer of the Order of Canada. Concerned about the social impact of AI and the objective that AI benefits all, he actively contributed to the Montreal Declaration for the Responsible Development of Artificial Intelligence.'},
        {'name': 'John Langford',
        'website': 'https://hunch.net',
        'affiliations': 'Microsoft Research',
        'img_path':"assets/img/john_langford.jpg",
        'bio': "John Langford is a computer scientist working in machine learning and learning theory. He is well known for work on the Isomap embedding algorithm, CAPTCHA challenges, Cover Trees for nearest neighbor search, Contextual Bandits for reinforcement learning applications, and learning reductions. John is the author of the blog hunch.net and the principal developer of Vowpal Wabbit. He works at Microsoft Research New York, of which he was one of the founding members, and was previously affiliated with Yahoo! Research, Toyota Technological Institute at Chicago, and IBM's Watson Research Center. He studied Physics and Computer Science at the California Institute of Technology, earning a double bachelor's degree in 1997, and he received his Ph.D. in Computer Science from Carnegie Mellon University in the year of 2002. John was the program co-chair for the 2012 International Conference on Machine Learning (ICML), general chair for the 2016 ICML, and is the President of ICML from 2019‚Äì2021."},
        {'name': 'Kyunghyun Cho',
        'website': 'https://kyunghyuncho.me/',
        'affiliations': 'New York University',
        'img_path':"assets/img/kyunghyun_cho.jpeg",
        'bio': 'Kyunghyun Cho is an associate professor of computer science and data science at New York University and CIFAR Fellow of Learning in Machines & Brains. He is also a senior director of frontier research at the Prescient Design team within Genentech Research & Early Development (gRED). He was a research scientist at Facebook AI Research from June 2017 to May 2020 and a postdoctoral fellow at University of Montreal until Summer 2015 under the supervision of Prof. Yoshua Bengio, after receiving PhD and MSc degrees from Aalto University April 2011 and April 2014, respectively, under the supervision of Prof. Juha Karhunen, Dr. Tapani Raiko and Dr. Alexander Ilin.'}
        ]
    }
]
